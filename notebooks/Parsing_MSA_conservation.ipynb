{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook is based on the code of [ConservFold](https://www.rodrigueslab.com/resources). The input data that you need to upload is:\n",
        "1. The AlphaFold2 (AF2) model in .pdb format\n",
        "2. A set of custom homologous sequences of interest in .fasta format\n",
        "\n",
        "This notebook will take these inputs and compute a custom MSA to detect the most conserved amino acids in relation to the sequence from the AF2 model. Then, from this MSA compute the Weblogo entropy (AKA conservation score) and parse it into the AF2 model.\n",
        "\n",
        "\n",
        "* Written by GAMA ([@miangoar on Twitter](https://twitter.com/miangoar))\n",
        "* Date: 04/2024"
      ],
      "metadata": {
        "id": "IYLZiQUwJUG4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "Oaqb4SPmXbvP",
        "outputId": "ab64a3fb-4a54-4cc7-cbfc-30c2e4fb29aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.7/571.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hseqkit\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "\n",
            "Installing base environment...\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Channels:\n",
            " - defaults\n",
            " - bioconda\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - bioconda::mafft\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    mafft-7.505                |       hec16e2b_0         3.5 MB  bioconda\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         3.5 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  mafft              bioconda/linux-64::mafft-7.505-hec16e2b_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "                                                                        \n",
            "Preparing transaction: / \b\bdone\n",
            "Verifying transaction: \\ \b\bdone\n",
            "Executing transaction: / \b\bdone\n"
          ]
        }
      ],
      "source": [
        "#@title 1) Install libraries\n",
        "# @markdown\n",
        "! pip install -Uqqq weblogo\n",
        "! pip install -Uqqq biopython\n",
        "! pip install -Uqqq pdb-tools\n",
        "\n",
        "# seqkit install\n",
        "! curl -s -O -L https://github.com/shenwei356/seqkit/releases/download/v2.8.0/seqkit_linux_amd64.tar.gz\n",
        "! tar -xzvf seqkit_linux_amd64.tar.gz\n",
        "! cp seqkit /usr/local/bin/\n",
        "\n",
        "# mafft install\n",
        "! wget -qO ac.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "! bash ./ac.sh -bfp /usr/local\n",
        "! conda install bioconda::mafft -y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2) Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from Bio.PDB import PDBParser, PDBIO\n",
        "from Bio.PDB.StructureBuilder import StructureBuilder"
      ],
      "metadata": {
        "id": "sehRZX1SaRLw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3) Upload your AF2 model (in .pdb format)\n",
        "# @markdown\n",
        "\n",
        "# get the original name and rename it\n",
        "upload = files.upload()\n",
        "upload_file = list(upload.keys())[0]\n",
        "os.rename(upload_file, \"af2_model.pdb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "cellView": "form",
        "id": "enY2T0V-AZUN",
        "outputId": "6e87b8ad-ed6e-4e32-c1ce-6cf82ad5ea7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2e4daedd-0ef0-4d18-931b-74944b376d89\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2e4daedd-0ef0-4d18-931b-74944b376d89\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving my_af2_model.pdb to my_af2_model.pdb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4) Upload your custom homologous sequences (in .fasta format)\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# get the original name and rename it\n",
        "uploaded_filename = list(uploaded.keys())[0]\n",
        "os.rename(uploaded_filename, \"my_homologous_sequences.fasta\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "cellView": "form",
        "id": "6mWNydCnXhFL",
        "outputId": "f04e974c-2a0e-4f50-a2b2-b9b289c7fd42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fdf8b99d-8083-4452-9884-98cd05595cdc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fdf8b99d-8083-4452-9884-98cd05595cdc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving my_homologous_sequences.fasta to my_homologous_sequences.fasta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5) Compute the MSA\n",
        "\n",
        "# extract the seq from the af2 model\n",
        "! pdb_tofasta af2_model.pdb > af2_sequence.fasta\n",
        "! sed -i 's/^>[^ ]*/>af2_seq/' af2_sequence.fasta\n",
        "\n",
        "# concat the data\n",
        "! cat af2_sequence.fasta  my_homologous_sequences.fasta > input_sequences.fasta\n",
        "\n",
        "# rename the headers\n",
        "! seqkit replace -p \"\\t| \" -r '_' input_sequences.fasta  > sequences.fasta\n",
        "\n",
        "# run mafft\n",
        "! mafft --quiet sequences.fasta > msa.fasta\n",
        "\n",
        "# convert the msa to csv\n",
        "! seqkit fx2tab msa.fasta > msa.csv\n",
        "\n",
        "# create a df from the msa\n",
        "df = pd.read_csv(\"msa.csv\", sep=\"\\t\",names=[\"seq_id\",\"seq\"], usecols=[0,1])\n",
        "df.set_index('seq_id', inplace=True)\n",
        "\n",
        "# expand the df as a column per character in the msa\n",
        "new_df = pd.DataFrame(df['seq'].apply(list).tolist(), index=df.index)\n",
        "\n",
        "# extract the index that correspond to the AF2 seq\n",
        "af2_seq_data = new_df.loc[\"af2_seq\"]\n",
        "\n",
        "# detect the gapped columns in the df\n",
        "gaps = [idx for idx, val in af2_seq_data.items() if val == '-']\n",
        "\n",
        "# remove the gapped columns adn reformat the df\n",
        "clean = new_df.drop(columns=gaps, errors='ignore')\n",
        "clean['seq'] = clean.apply(lambda row: ''.join(row.astype(str)), axis=1)\n",
        "clean = clean[['seq']]\n",
        "clean.reset_index(inplace=True)\n",
        "clean.rename(columns={'index': clean.index.name}, inplace=False)\n",
        "\n",
        "# a fx to export fasta seqs\n",
        "def export_fasta(df, output_file):\n",
        "    with open(output_file, 'w') as f:\n",
        "        for index, row in df.iterrows():\n",
        "            f.write(f'>{row[\"seq_id\"]}\\n')\n",
        "            f.write(f'{row[\"seq\"]}\\n')\n",
        "\n",
        "# export the cleaned df as a fasta file\n",
        "export_fasta(clean, \"parsed_msa.fasta\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ljlyQDRddGZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6) PDB parser\n",
        "# @markdown This will download the file \"af2_model_weblogo.pdb\" that is the PDB file with the conservation score in the B-factor column.\n",
        "\n",
        "# @markdown Aditionally will download the file \"parsed_msa.fasta\" that is the custom MSA used to compute the conservation scores. This MSA can be visualized with tools like [ugene](https://ugene.net/).\n",
        "\n",
        "# compute the entropy from the msa\n",
        "!weblogo --format logodata < parsed_msa.fasta > weblogo.txt\n",
        "\n",
        "pdb_filename = f'af2_model.pdb' # the mode that comes from AF2\n",
        "weblogo_filename = 'weblogo.txt'\n",
        "\n",
        "# Read entropy values from weblogo.txt\n",
        "entropy_values = []\n",
        "with open(weblogo_filename, 'r') as weblogo_file:\n",
        "    for line in weblogo_file:\n",
        "        if not line.startswith(\"#\"):\n",
        "            data = line.split()\n",
        "            entropy = float(data[-4])  # Extract entropy value (4th from the end)\n",
        "            entropy_values.append(entropy)\n",
        "\n",
        "# Read the PDB file\n",
        "parser = PDBParser(QUIET=True)\n",
        "structure = parser.get_structure('protein', pdb_filename)\n",
        "\n",
        "# Modify the beta factor of atoms based on entropy values\n",
        "for model in structure:\n",
        "    for chain in model:\n",
        "        for residue in chain:\n",
        "            for atom in residue:\n",
        "                residue_index = residue.id[1] - 1  # Adjust for 0-based index\n",
        "                if residue_index < len(entropy_values):\n",
        "                    beta_factor = entropy_values[residue_index] ** 2  # Square the entropy value\n",
        "                    atom.set_bfactor(beta_factor)\n",
        "\n",
        "# Save the modified PDB file\n",
        "output_filename = pdb_filename.replace('af2_model.pdb', 'af2_model_weblogo.pdb')\n",
        "io = PDBIO()\n",
        "io.set_structure(structure)\n",
        "io.save(output_filename)\n",
        "\n",
        "# download the annotated pdb\n",
        "files.download('af2_model_weblogo.pdb')\n",
        "files.download('parsed_msa.fasta')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "cellView": "form",
        "id": "JaKwTTlKAwNC",
        "outputId": "86e162e2-f117-4e31-b0f3-6c7a231b6618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2aaf22b7-62c2-47f3-b8aa-3a2e23d2f211\", \"af2_model_weblogo.pdb\", 285776)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_483f38b5-5ec4-428c-b4c9-8ec2f6d36952\", \"parsed_msa.fasta\", 41144)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Set a function to see the most conserved position\n",
        "# @markdown This function takes the computed MSA and create a csv file in order to find the most conserved positions given a threshold (as percent 1 to 100)\n",
        "\n",
        "def find_conserved_positions(df, conservation_threshold):\n",
        "    # Convert the sequence into a character matrix\n",
        "    char_matrix = np.array([list(seq) for seq in df['seq']])\n",
        "\n",
        "    # Get the dimensions of the matrix\n",
        "    rows, cols = char_matrix.shape\n",
        "\n",
        "    # Create a DataFrame from the matrix\n",
        "    df_chars = pd.DataFrame(char_matrix, columns=[f'position_{i+1}' for i in range(cols)])\n",
        "\n",
        "    # Calculate the total number of rows in each column\n",
        "    total_rows = df_chars.apply(lambda x: x.count())\n",
        "\n",
        "    # Initialize a dictionary to store the results\n",
        "    result_dict = {}\n",
        "\n",
        "    # Iterate over each column of the DataFrame\n",
        "    for col in df_chars.columns:\n",
        "        # Calculate the frequency of each character in the current column\n",
        "        char_counts = df_chars[col].value_counts().to_dict()\n",
        "        # Calculate the conservation percentage for each character\n",
        "        conservation_percentages = {char: count / total_rows[col] * 100 for char, count in char_counts.items()}\n",
        "        # Add the results to the final dictionary\n",
        "        result_dict[col] = conservation_percentages\n",
        "\n",
        "    # Filter the columns that have at least one character with a conservation percentage equal to or greater than the conservation threshold\n",
        "    filtered_result = {}\n",
        "    for col, percentages in result_dict.items():\n",
        "        non_dash_percentages = {char: percentage for char, percentage in percentages.items() if char != \"-\"}\n",
        "        if any(percentage >= conservation_threshold for percentage in non_dash_percentages.values()):\n",
        "            filtered_result[col] = non_dash_percentages\n",
        "\n",
        "    # Create a dictionary with the conserved positions with a percentage equal to or greater than the conservation threshold\n",
        "    conserved_positions = {}\n",
        "    for col, percentages in filtered_result.items():\n",
        "        conserved_chars = {char: percentage for char, percentage in percentages.items() if percentage >= conservation_threshold}\n",
        "        if conserved_chars:\n",
        "            conserved_positions[col] = conserved_chars\n",
        "\n",
        "    return conserved_positions"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_ESBTgkRZaRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Run the function\n",
        "# @markdown Set the conservation threshold that you want. It will show the specific positions that passed the threshold.\n",
        "\n",
        "conservation_threshold = \"90\" #@param {type:\"string\"}\n",
        "conserved_positions = find_conserved_positions(clean, int(conservation_threshold))\n",
        "print(f\"Positions conserved above {conservation_threshold}%\")\n",
        "conserved_positions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "q6KsIW_3ea_J",
        "outputId": "e11170f7-33dc-47b5-aa61-f85b48cddb92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positions conserved above 90%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'position_165': {'E': 95.1219512195122},\n",
              " 'position_169': {'V': 92.6829268292683},\n",
              " 'position_171': {'R': 92.6829268292683},\n",
              " 'position_175': {'L': 95.1219512195122},\n",
              " 'position_180': {'H': 93.90243902439023},\n",
              " 'position_210': {'P': 93.90243902439023},\n",
              " 'position_229': {'F': 95.1219512195122},\n",
              " 'position_240': {'N': 92.6829268292683},\n",
              " 'position_315': {'W': 90.2439024390244}}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}